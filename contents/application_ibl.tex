\chapter{Application: Image Based Lighting}
\label{ch:application_ibl}
In this chapter we start by describing image based lighting shortly.
Following that the approach of Karl\'ik et al. is explained to use in image based lighting.
\todo{Explain the contents of this chapter (at the end)}


\section{Image Based Lighting}
\label{sec:ibl}
Creating realistic lighting for a scene can be very complex and time consuming.
To avoid modelling a lighting environment a commonly used method is to create an image of a real world environment
and using that for the direct illumination of a scene.
This approach is called image based lighting and was introduced back in 1998 by Debevec in~\cite{debevec}.\\
To get the lighting of a scene in the real world you could place a mirror sphere in the middle of your scene
and the a photo of that sphere ideally from far away
so the camera itself doesn't take up a large part of the scene.
This method is called sphere mapping.
During rendering you place your scene in the center of that textured sphere
and if a shadow ray doesn't hit any object of the scene you read out the texel
on the sphere that corresponds to the direction of the ray.\\
A different method is to take six pictures of the scene from the top, bottom, left, right, front and back
and then use the same evaluation method as with the sphere with the direction of the shadow ray direction
to get the texel from the environment map.
For more information on how to use environment maps/image based lighting consider~\cite{environment_map}.


\section{MIS Compensation in Image Based Lighting}
\label{sec:misc_ibl}
Here we will discuss the image based lighting application example from Karl\'ik et al. in~\cite[Section~6-7]{Karlik2019}.


\subsection{Setup}
\label{sec:ibl_setup}
They calculate the unoccluded direct illumination with the following rendering equation:
\begin{equation}
    \label{eq:ibl_render_equation}
    L_{dir}(x, \omega_o) = \int_{H(n)} L_I(\omega_i) \rho(x, \omega_i, \omega_o) |n \cdot \omega_i|_+ d\omega_i.
\end{equation}
$ x $ is the surface position and $ \omega_o $ the outgoing view direction.
The integration domain $ H(n) $ is the upper hemisphere centered around the normal $ n $.
The HDR environment map is used through $ L_I(w_i) $,
$ \rho(x, \omega_i, \omega_o) $ corresponds to the BRDF at position $ x $
with incoming direction $ \omega_i $ and outgoing direction $ \omega_o $.
$ |n \cdot \omega_i|_+ $ is the positive cosine of the angle between the normal and the incoming direction i.e. $ max\{0, |n \cdot \omega_i|\} $.\\
In a standard Monte Carlo renderer two pdfs would be used,
one proportional to the BRDF-cosine product and another one proportional to the environment map.
Those two would then be combined in MIS with the balance heuristic.
Generally the BRDF-cosine product pdf is given analytically and depends on the position, the outgoing and the incoming direction
whereas the environment map pdf is mostly tabulated and only depends on the incoming direction.
Since the second one is easier to modify,
that one was used as the free pdf in their work.


\subsection{PDF solutions}
\label{sec:ibl_pdfs}
To get the compensated pdf sampling technique equation~\ref{eq:ibl_render_equation}
and the BRDF sampling pdf $ p_{\rho}(x, \omega_i, \omega_o) $ are inserted into equation~\ref{eq:valid_compensated_pdf}
to get $$ \tilde{p}_I(x, \omega_i, \omega_o) = \frac{1}{b} max\{0, \frac{f_I(x, \omega_i, \omega_o)}{c_I L_{dir}(x, \omega_o)} - \frac{1 - c_I}{c_I} p_\rho(x, \omega_i, \omega_o)\} $$
where $ f_I(x, \omega_i, \omega_o) = L_I(\omega_i) \rho(x, \omega_i, \omega_o) |n \cdot \omega_i|_+ $,
$ c_I $ is the proportion of samples for the free pdf and b is the normalization factor to make it integrate to one.
Since this solution depends on the position, the incoming and the outgoing direction they proposed a simpler solution we will show in the upcoming section.


\subsubsection{Normal-dependend solution}
\label{sec:ibl_normal_dependent}
To remove the dependency on the position and the outgoing direction they assumed a Lambertian BRDF with albedo $ \rho \equiv \frac{1}{\pi} $
which yields: $$ \tilde{p}_I^{nd}(\omega_i, n) = \frac{1}{b_{nd}} max\{0, \frac{f_{nd}(\omega_i, n)}{c_I \int_{H(n)} f_{nd}(\omega, n) d\omega} - \frac{1 - c_I}{c_I} \frac{|n \cdot \omega_i|_+}{\pi}\}. $$
This formula does depend on the surface normal,
but it can still be precomputed for a number of directions.
Since this solution is more practical than the more general one before it still might require changes in the rendering implementation.
Therefore they introduced one more solution that uses less memory and has even less dependencies.


\subsubsection{Normal-independend solution}
\label{sec:ibl_normal_independend}
This method averages over all normal directions (for a detailed explanation please refer to~\cite[Appendix~D]{Karlik2019})
to get a pdf that is only dependent on the incoming direction: $$ p_I^{ni}(\omega_i) = \frac{1}{b_{ni}} max\{0, L_I(\omega_i) - 2 (1 - c_I) \bar{L}_I\}. $$
As above $ b_{ni} $ is the normalization factor and $ \bar{L}_I $ is the average of the HDR map luminance.
If we look close we see that the formula corresponds to a simple subtraction from the complete environment map and then re-normalizing it.


\subsection{Evaluation}
\label{sec:ibl_evalutiona}
setup with figure
figure of results and brdfs






\todo{Explain how their approach improves ibl variance}


\todo{If space left show results}